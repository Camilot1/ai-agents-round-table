# AI agents round-table

## Назначение
- Многоагентная площадка, где отделы продаж, производства и логистики разделяются на собственные потоки, но работают поверх единого ядра `LLMAgent`.
- Телеграм-бот на базе `aiogram 3`, оборачивающий локальную или облачную LLM (Gemma) и автоматически подключающий инструменты MCP.
- Опциональный HTTP/A2A сервер, чтобы другие процессы или агенты могли вызывать текущего ассистента через протокол Agent-to-Agent.
- Пиринговые вызовы (`agent.<Имя>`): ассистент может переслать запрос в другой отдел, если тот присутствует в конфигурации `A2A_PEERS_CONFIG`.
- Набор тематических MCP-серверов, которые поднимаются автоматически по списку из `MCP_SERVERS_CONFIG` и расширяют возможные действия агента.

## Архитектура
- `scripts/main.py` — точка входа, которая загружает `.env`, настраивает журналы, собирает список MCP серверов и запускает выбранный режим (`telegram`, `a2a`, `both`).
- `scripts/telegram_bot.py` — реализация классов `LLMAgent`, `TelegramBot`, клиентов MCP (`MCPToolClient`) и пирингов (`A2APeerClient`). Здесь же логика JSON-протокола, через который модель принимает решение о вызове инструментов.
- `scripts/a2a_agent.py` — обертка над `python-a2a`, превращающая `LLMAgent` в HTTP-службу с описанием навыков и трансляцией задач в сообщения модели.
- `scripts/a2a_router.py` — простой HTTP-маршрутизатор, способный пересылать запросы к нескольким агентам (удобно для ручного теста или интеграции).
- `scripts/mcp_servers/*.py` — тематические MCP инструменты (продажи, производство, логистика, утилиты). Список активных серверов определяется JSON-конфигурацией.

```
.
├─ configs/
│  ├─ a2a_agents.json              # карта доступных агентов по протоколу A2A
│  ├─ mcp_servers_*.json           # списки MCP-серверов для конкретных ролей
│  └─ envs/                        # примерные .env для каждого отдела
├─ logs/                           # сюда пишутся журналы (создается автоматически)
├─ scripts/
│  ├─ main.py
│  ├─ telegram_bot.py
│  ├─ a2a_agent.py
│  ├─ a2a_router.py
│  └─ mcp_servers/
│     ├─ mcp_server_sells.py
│     ├─ mcp_server_production.py
│     ├─ mcp_server_logistics.py
│     ├─ mcp_server_time.py
│     └─ mcp_server_random.py
├─ run_*.bat                       # сценарии быстрого запуска под Windows
├─ requirements.txt
└─ OLD_README_AGENT.md             # текущий документ
```

## Требования
- Python 3.11+ (виртуальное окружение рекомендуется).
- Доступ в интернет для Hugging Face, если модель запускается как облачный inference (при работе с локальным GGUF не требуется).
- Пакет `llama-cpp-python` — нужен только при использовании локальной модели (`LOCAL_MODEL_PATH` указывает на GGUF файл).
- Аккаунт и токен Hugging Face (если используется удаленная модель).

## Установка
1. Создайте и активируйте виртуальное окружение:
   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # Linux/macOS
   ```
2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```
3. (Опционально) Для локальной GGUF модели установите:
   ```bash
   pip install llama-cpp-python
   ```
4. Скопируйте соответствующий пример из `configs/envs/*.env` и адаптируйте значения под свою среду.

## Настройка окружения
Пример `.env` лежит в корне, готовые конфигурации на отделы — в `configs/envs`. Ниже ключевые переменные:

| Переменная | Обязательна | Описание |
| --- | --- | --- |
| `TELEGRAM_BOT_TOKEN` | да | Токен бота. Не храните реальный токен в репозитории. |
| `ALLOWED_USERS` | нет | Список ID через запятую. Если пусто — бот доступен всем. |
| `HF_TOKEN` | да* | Токен Hugging Face (нужен при удаленной модели). |
| `HF_MODEL_ID` | нет | Идентификатор модели на HF. По умолчанию `google/gemma-3-1b-it`. |
| `HF_INFERENCE_PROVIDER` | нет | Имя провайдера HF Inference (оставьте `hf-inference`, если не уверены). |
| `LOCAL_MODEL_PATH` | да* | Путь к локальному GGUF (используйте вместо `HF_MODEL_ID`, если запускаете модель офлайн). |
| `MCP_SERVERS_CONFIG` | да | JSON-файл со списком MCP-серверов для запуска. |
| `A2A_ENABLED` | нет | `true/false` — поднимать ли HTTP A2A сервер. |
| `A2A_HOST`, `A2A_PORT` | нет | Адрес и порт A2A. Все агенты должны использовать разные порты. |
| `A2A_NAME`, `A2A_DESCRIPTION`, `A2A_VERSION`, `A2A_PUBLIC_URL` | нет | Метаданные агента, отображаемые в A2A. |
| `A2A_PEERS_CONFIG` | нет | JSON с картой соседних агентов. Текущий агент исключается автоматически. |
| `LOG_FILE` | нет | Пользовательский путь к файлу журнала. Если не указан — создается `logs/<имя>.log`. |

\* Используйте либо `HF_TOKEN` + `HF_MODEL_ID`, либо `LOCAL_MODEL_PATH`. При локальной модели клиент `AsyncInferenceClient` не создается, зато нужно наличие `llama-cpp-python`.

## MCP инструменты
- **Продажи** (`scripts/mcp_servers/mcp_server_sells.py`, `configs/mcp_servers_sells_agent.json`): активны инструменты `get_available_products`, `calculate_order_price`, `get_available_slots`, `get_managers_info`. Остальные заготовки можно включить, раскомментировав декоратор `@mcp.tool()`.
- **Производство** (`scripts/mcp_servers/mcp_server_production.py`): обработка заявок (`submit_order_to_production`), поиск заказов (`get_production_orders_by_status`, `get_production_order_by_id`). Скрипт поддерживает передачу параметра `--transport` (`stdio` по умолчанию), но при запуске из агента используется именно STDIO.
- **Логистика** (`scripts/mcp_servers/mcp_server_logistics.py`): пример расчета стоимости доставки (`calculate_shipping_cost`). Остальные утилиты (статусы маршрутов, складов, автопарк) подготовлены и подключаются раскомментированием декоратора.
- **Утилиты** (`mcp_server_time.py`, `mcp_server_random.py`) — базовые примеры, которые можно добавить в любой конфиг MCP.

Каждый JSON в `configs/mcp_servers_*.json` описывает набор серверов. Поле `script` может быть заменено на `command`, если требуется запускать внешний бинарник; `{python}` автоматически подменяется на текущий интерпретатор.

## A2A конфигурация и маршрутизатор
- `configs/a2a_agents.json` содержит карту вида `"ИмяАгента": "http://host:port"`. Текущий агент игнорирует запись с собственным `A2A_NAME`, но остальные становятся доступными как инструменты `agent.<Имя>`.
- Если требуется центральная точка входа, поднимите маршрутизатор:
  ```bash
  python scripts/a2a_router.py --config configs/a2a_agents.json --host 127.0.0.1 --port 7080
  ```
  - `GET /agents` — список зарегистрированных агентов.
  - `POST /relay` — пересылка запроса: `{"target": "SellsAgent", "message": "...", "conversation_id": "optional"}`.
- Пакет `python-a2a` поддерживает стандарт Google A2A, поэтому агент можно регистрировать в сторонних системах или подключать к общему роутеру.

## Запуск
- Универсальная команда:
  ```bash
  python scripts/main.py --mode <telegram|a2a|both> --env path/to/env
  ```
  Пример: `python scripts/main.py --mode both --env configs/envs/sells_agent.env` стартует бота и A2A сервер отдела продаж.
- Дополнительные параметры CLI (`--a2a-host`, `--a2a-port`, `--a2a-name`, `--a2a-description`, `--a2a-version`, `--a2a-url`) позволяют переопределить значения из `.env` без его правки.
- Готовые BAT-файлы для Windows:
  - `run_sells_agent.bat`
  - `run_production_agent.bat`
  - `run_logistics_agent.bat`
  - `run_a2a_router.bat`
  Они устанавливают нужные переменные и вызывают `python scripts\main.py ...`. Дополнительные аргументы можно передать в конец команды.

## Telegram-бот
- Обрабатывает `/start` и обычные сообщения. Неавторизованные пользователи (если `ALLOWED_USERS` задан) получают вежливый отказ.
- Передает пользователю статус "печатает" (`ChatAction.TYPING`) и дублирует ошибки форматирования Markdown как plain text.
- Под капотом `LLMAgent` хранит историю сообщений на пользователя и может дважды подряд вызвать инструмент, прежде чем вернуть итоговый ответ.

## Логирование и диагностика
- Консольная конфигурация `logging.basicConfig` активна всегда; при старте создается файл с ротацией (5 MB, до трех резервных копий) в каталоге `logs/`, если не задан `LOG_FILE`.
- Каждое обращение к инструменту MCP или пирам логируется (название, аргументы, статус). При ошибке соединения клиент закрывает STDIO-сеансы и поднимет их заново при следующем запросе.
- В каталоге `logs/` остаются отдельные файлы для каждого агента: это упрощает анализ диалога и мониторинг ошибок.

## Типовой сценарий взаимодействия
1. Пользователь пишет в Telegram. Бот проверяет доступ и добавляет сообщение в контекст моделей.
2. Модель формирует JSON с действием. Если это `tool`, `LLMAgent` вызывает MCP инструмент или пирам через A2A.
3. Результат инструмента вкладывается в историю, модель запрашивается повторно (до двух итераций), затем высылается финальный ответ.
4. При сложных запросах ассистент может обратиться к другому агенту (`agent.<Имя>`), который, в свою очередь, использует собственные MCP-инструменты.
5. Все шаги журналируются, что позволяет анализировать цепочку решений и корректировать конфигурации MCP или A2A.

Гибко изменяйте состав MCP и A2A конфигураций под нужный отдел: для добавления нового инструмента достаточно создать скрипт в `scripts/mcp_servers/`, описать его в JSON и обновить `.env` агента. Новые отделы подключаются теми же шагами, что и существующие — копируйте любую `configs/envs/*.env`, меняйте порты и описания, и добавляйте запись в `configs/a2a_agents.json`.
